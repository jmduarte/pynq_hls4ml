{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PYNQ\n",
    "This notebook is to run on the PYNQ! You'll need the bitfile and \"hardware handoff\" file from part 1.\n",
    "The files should be named `hls4ml_demo.bit` and `hls4ml_demo.hwh`. In principle they can be named anything you like, but the two files do need to have the same name apart from the extension.\n",
    "You should have the files:\n",
    "- `hls4ml_demo.bit`\n",
    "- `hls4ml_demo.hwh`\n",
    "- `X_test.npy`\n",
    "- `y_hls.npy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "from pynq import MMIO\n",
    "import numpy as np\n",
    "import struct\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load bitfile (overlay)\n",
    "We will load the bitfile we generated onto the PL of the PYNQ SoC. The `.hwh` is used to define the Python interface for us, nice!\n",
    "https://pynq.readthedocs.io/en/latest/overlay_design_methodology/python_overlay_api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = Overlay(\"./hls4ml_demo.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check\n",
    "This should return `True` if it loaded, otherwise something went wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.is_loaded()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IP\n",
    "This is the `hls4ml` generated IP (our NN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = overlay.myproject_axi_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register map\n",
    "These are the registers of our IP which we can read/write.\n",
    "There should be one for NN inputs and one for its outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ip.register_map)\n",
    "print(\"Memory_in_V.address: \" + str(ip.register_map.Memory_in_V.address))\n",
    "print(\"Memory_out_V.address: \" + str(ip.register_map.Memory_out_V.address))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMIO\n",
    "We used the `s_axilite` interface, so we will communicate using the MMIO.\n",
    "In the HLS top level you would see, for example:\n",
    "``` \n",
    "    #pragma HLS INTERFACE ap_ctrl_none port=return\n",
    "    #pragma HLS INTERFACE s_axilite port=in\n",
    "    #pragma HLS INTERFACE s_axilite port=out\n",
    "```\n",
    "This is the most simple interface, but also the slowest. One of the future tasks is to use a higher performance connection like DMA.\n",
    "https://pynq.readthedocs.io/en/latest/overlay_design_methodology/pspl_interface.html\n",
    "\n",
    "We need to specifiy the start address and width of the MMIO address space for each interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_mmio = MMIO(ip.mmio.base_addr + ip.register_map.Memory_in_V.address, 8 * 4)\n",
    "ou_mmio = MMIO(ip.mmio.base_addr + ip.register_map.Memory_out_V.address, 3 * 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Load the jet tagging dataset that we saved on the host earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('./X_test.npy').astype(np.float32)\n",
    "X = X[:1000]\n",
    "y = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver / Encoding, Decoding\n",
    "Our hls4ml NN used `ap_fixed<16,6>` for the input and output data types. Our dataset in the `X_test.npy` file contains `float` values. We need to make a few transformations to write to the NN.\n",
    "- Cast to `int`. We need to 'shift' our `float`s up by 10 bits (the number of fractional bits of the `<16,6>` to 'align' the bits properly. This is `encode`\n",
    "- Pack a pair of bits. The AXI interface here uses 32 bit data, but our values need to be 16 bits. We need to pack 2 x 16 bit values into 1x32 bit integer. This is `encode_pair`\n",
    "\n",
    "At the output of the NN we need to do the reverse:\n",
    "\n",
    "- Slice each 32 bit integer into two 16 bit values (the upper and lower 16 bits). This uses bit-masking (the ` yab & 0x0000ffff` in `decode_pair`)\n",
    "- Shift back down to the physical range by 10 bits\n",
    "\n",
    "In future this might become a 'driver': https://pynq.readthedocs.io/en/latest/overlay_design_methodology/python_overlay_api.html#customising-drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(xi):\n",
    "    return int(round(xi * 2**10))\n",
    "\n",
    "def encode_pair(xa, xb):\n",
    "    return encode(xa) + encode(xb) * 2**16\n",
    "    #return encode(xb) + encode(xa) * 2**16\n",
    "\n",
    "def decode(yi):\n",
    "    return yi * 2**-10\n",
    "\n",
    "def decode_pair(yab):\n",
    "    ya = (yab & 0x0000ffff) * 2**-10\n",
    "    ya = ya if ya < 32 else ya - 64\n",
    "    yb = (yab & 0xffff0000) * 2**-26\n",
    "    yb = yb if yb < 32 else yb - 64\n",
    "    return ya, yb\n",
    "\n",
    "def get_output(mmio):\n",
    "    y = np.zeros(6)\n",
    "    for i in range(3):\n",
    "        yi = decode_pair(mmio.read(4 * i))\n",
    "        y[2*i], y[2*i+1] = yi[0], yi[1]\n",
    "    return y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the inference!\n",
    "Now we actually write the data to our hls4ml IP with `in_mmio.write` and read the output with `get_output(ou_mmio)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timea = datetime.now()\n",
    "for Xi in X:\n",
    "    for i in range(8):\n",
    "        xab = encode_pair(Xi[2*i], Xi[2*i+1])\n",
    "        in_mmio.write(4 * i, xab)\n",
    "    y.append(get_output(ou_mmio))\n",
    "timeb = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time\n",
    "How long did it take? You'll notice the time per inference is much higher than the IP latency or II. We're totally dominated by the IO and encoding/decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dt(timea, timeb, N):\n",
    "    dt = (timeb - timea) \n",
    "    dts = dt.seconds + dt.microseconds * 10**-6\n",
    "    rate = len(X) / dts\n",
    "    print(\"Classified {} samples in {} seconds ({} inferences / s)\".format(N, dts, rate))\n",
    "    \n",
    "print_dt(timea, timeb, len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare\n",
    "Load the `csim` dataset and print a few values out. Hopefully they're basically the same! There could be some small difference due to the encoding / decoding being different to convert our `float`s to `ap_fixed<16,6>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hls = np.load('./y_hls.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running on the board:\")\n",
    "for i in range(5):\n",
    "    print(y[i])\n",
    "print(\"Running on the CPU csim:\")\n",
    "for i in range(5):\n",
    "    print(y_hls[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data\n",
    "Now let's classify the whole dataset and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('./X_test.npy').astype(np.float32)\n",
    "y = []\n",
    "timea = datetime.now()\n",
    "time0 = datetime.now()\n",
    "for iXi, Xi in enumerate(X):\n",
    "    for i in range(8):\n",
    "        xab = encode_pair(Xi[2*i], Xi[2*i+1])\n",
    "        in_mmio.write(4 * i, xab)\n",
    "    y.append(get_output(ou_mmio))\n",
    "    if iXi % 5000 == 0:\n",
    "        time1 = datetime.now()\n",
    "        print_dt(time0, time1, 5000)\n",
    "        time0 = datetime.now()\n",
    "\n",
    "timeb = datetime.now()\n",
    "print_dt(timea, timeb, len(X))\n",
    "np.save('y_pynq.npy', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue to part 3\n",
    "Download/Upload the `y_pynq.npy` back to the host where you ran the part 1 notebook to make a final comparison in the part 3 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
